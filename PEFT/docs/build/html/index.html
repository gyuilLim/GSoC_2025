<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>PEFT: Parameter-Efficient Fine-Tuning (LoRA &amp; DoRA) for Classification &#8212; peft 25.08.22 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=61cd365c" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=12dfc556" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="_static/documentation_options.js?v=1725c997"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="peft-parameter-efficient-fine-tuning-lora-dora-for-classification">
<h1>PEFT: Parameter-Efficient Fine-Tuning (LoRA &amp; DoRA) for Classification<a class="headerlink" href="#peft-parameter-efficient-fine-tuning-lora-dora-for-classification" title="Link to this heading">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PEFT (LoRA, DoRA) is only supported for VisionTransformer models.
See the method in otx.backend.native.models.classification.utils.peft</p>
</div>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">¶</a></h2>
<p>OpenVINO™ Training Extensions supports Parameter-Efficient Fine-Tuning (PEFT) for Transformer classifiers via Low Rank Adaptation (LoRA) and Weight-Decomposed Low-Rank Adaptation (DoRA).
These methods adapt pre-trained models with a small number of additional parameters instead of fully fine-tuning all weights.</p>
</section>
<section id="benefits">
<h2>Benefits<a class="headerlink" href="#benefits" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><strong>Efficiency</strong>: Minimal extra parameters and faster adaptation.</p></li>
<li><p><strong>Performance</strong>: Competitive accuracy compared to full fine-tuning.</p></li>
<li><p><strong>Flexibility</strong>: Apply LoRA or DoRA selectively to model components.</p></li>
</ul>
</section>
<section id="supported">
<h2>Supported<a class="headerlink" href="#supported" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><strong>Backbones</strong>: Vision Transformer family (e.g., DINOv2)</p></li>
<li><p><strong>Tasks</strong>: Multiclass, Multi-label, Hierarchical Label Classification</p></li>
</ul>
</section>
<section id="how-to-use-peft-in-openvino-training-extensions">
<h2>How to Use PEFT in OpenVINO™ Training Extensions<a class="headerlink" href="#how-to-use-peft-in-openvino-training-extensions" title="Link to this heading">¶</a></h2>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
API</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">training_extensions.src.otx.backend.native.models.classification.multiclass_models.vit</span> <span class="kn">import</span> <span class="n">VisionTransformerMulticlassCls</span>

<span class="c1"># Choose one: &quot;lora&quot; or &quot;dora&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VisionTransformerForMulticlassCls</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">peft</span><span class="o">=</span><span class="s2">&quot;lora&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
CLI</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>otx<span class="o">)</span><span class="w"> </span>$<span class="w"> </span>otx<span class="w"> </span>train<span class="w"> </span>...<span class="w"> </span>--model.peft<span class="w"> </span>dora
</pre></div>
</div>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
YAML</label><div class="sd-tab-content docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">task</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MULTI_CLASS_CLS</span>
<span class="nt">model</span><span class="p">:</span>
<span class="w">   </span><span class="nt">class_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">otx.backend.native.models.classification.multiclass_models.vit.VisionTransformerMulticlassCls</span>
<span class="w">   </span><span class="nt">init_args</span><span class="p">:</span>
<span class="w">      </span><span class="nt">label_info</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span>
<span class="w">      </span><span class="nt">model_name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;dinov2-small&quot;</span>
<span class="w">      </span><span class="nt">peft</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&quot;</span>

<span class="w">      </span><span class="nt">optimizer</span><span class="p">:</span>
<span class="w">         </span><span class="nt">class_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.optim.AdamW</span>
<span class="w">         </span><span class="nt">init_args</span><span class="p">:</span>
<span class="w">            </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0001</span>
<span class="w">            </span><span class="nt">weight_decay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="#">peft</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, gyuil.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>